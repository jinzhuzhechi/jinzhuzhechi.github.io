<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>参观万林博物馆</title>
    <link href="/posts/62398/"/>
    <url>/posts/62398/</url>
    
    <content type="html"><![CDATA[<p>  这尊佛像为 15.8 米。在这里我们做了一个 5 比 4 的复原。因此我们面前的这尊复原的涅槃像，它的长度为 12 米。在涅槃像的上方有非常多很精美的壁画，上面绘画的内容也非常多。最上方是菩萨，菩萨的下方是罗汉以及护法等等。在涅槃这样的它的右侧这样的一个称为十大弟子，上面所描绘的正是释伽牟尼的十大弟子。释加牟尼涅槃的时候全部的场面，我们可以近距离观察到我右手边的这个，大家可以走仔细的观察。可以看到，这幅画是各国王子，大家可以看到他们手里都是刀和剑。那他们在干什么呢？在挖心剖腹，可以看得很清楚。这个是在剖腹是吧，那边是在割耳朵，这个是挖心，他们就是用极端自残的方式来表达自己对释迦摩尼逝世的这种哀词和痛苦。那么与各国太子形成鲜明对比的是什么？大家可以转身向后望去。就是我们的这个画，我们可以看到它释迦牟尼的弟子面部都非常丰满，但神情十分的纯净活跃，毫无凡人的痛苦。<br><img src="https://s2.loli.net/2022/10/03/bxDZBtkmcyFQOUr.jpg" alt="万林1.png"></p><p>  各个时期各个朝代的人物壁画。那么其中绝大多数是供养人画像。什么是供养人呢？就是在当时一些名门望族她们出资开凿洞窟，出资画壁画，就把这些出资的人称为供养的人。</p><p>  接下来给大家讲的这幅壁画讲了一个非常出名的故事，就是割肉喂鹰的故事。这个故事是这样的，这只白色是一只鹰，青色的是鸽子。这只白色鹰在追逐这个鸽子，于是这个鸽子就逃到了我们这幅画的主人公。他叫尸毗王。他是印度的一个国王，这个尸毗王心地非常的善良，他既不想让这只鸽子被吃掉，又不想让鹰饿死。唉于是他就对鹰说我拿别的肉换给你好不好？但这只鹰说我非常的挑剔，我只吃新鲜的肉。于是这个视频大家可以看到，就派人割自己的肉来喂给这只鹰。然后这只鹰他又说了，你既然心地那么善良，讲求众生皆平等的这样的思想，那么就要让你背上肉的重量和这只鸽子的重量是相等的。于是我们就可以在右下角可以看到尸毗王又派人去拿了一杆秤，秤上称的是什么呢？就是这只鸽子和它自己肉，让它们的重量相等，体现这种众生皆平等的思想。</p><p><img src="https://s2.loli.net/2022/10/03/kNH4tdGubvmlOj9.png" alt="万林2.png"></p><p>  这个是九色鹿的故事，这个故事显示大家已经非常的熟悉了，但是我在这里给大家讲的是它的一个观看顺序。这幅画正确的观看顺序是先看最左侧。对，是九色鹿在水中驮起了一个溺水的人，然后这个溺水就对这个九色鹿表示感谢。同时九色鹿说，说你不要把我的故事讲给外人。接下来我们的视线来到我们的画幅的最右边，这里是一个国王和王后，这只王这个这只这这位王后他有一日做梦就梦到了说森林深处有一只非常美丽的九色鹿。于是就对国王讲了，国王听了之后就出重金来派兵去捉拿这个九色鹿。同时我们可以看到这个就是刚之前那个溺水的人，他就跑来告密说我知道九色鹿在哪里。于是国王和王后就在森林深处见到了九色鹿。同时九色鹿就对他讲了这个事情的原委说我救了这个溺水的人，但是这个人却是出卖了。我国王听了之后，于是便下令放了九色鹿，同时处死了这个溺水的人。所以这幅画的观看顺序是先看最左侧，然后从右向中间依次看。这样排布的一个寓意就是让整幅画的最高超就是在森林深处遇到九色鹿的这部分，排布在了整幅画最中央的位置。</p><p><img src="https://s2.loli.net/2022/10/03/CJAvrZpSPyRIkj2.png" alt="万林3.png"></p><p>  接下来大家可以看到三幅非常大的地方。那么这种类型的对话有个名字叫做经变。那什么是经变呢？就是应该在当时不是每个人能接触的到佛经接触到佛经，就不一定能够读得懂佛经。于是就用这种通俗易懂的方式向大众传播佛经当中的教义。我要给大家讲的这一幅称为弥勒经变。这个弥勒经验它所描绘的场面实际是人们想象出来的一个场面。它想象出来是几亿年之后的这样的一个场面，中间有很多的幻想。有非常多非常有意思的小故事，我一一讲给大家。我们可以看这些画的细节之处。（左中）首先在这里这个有两个人在耕种，还是跟我们耕种方式没有什么差异。但是他们这个是播种，一次就能收获七次就是一种七收。（左下）同时我们可以看到在这里。这块大家看有个土包，土包里做了一个白发苍苍的老翁。其实按照这幅画的它的一个示意，这个老翁已经 84,000 岁了，告诉我做的土包也就是它的坟墓。呦所以说这块想表达的是一个在几亿年之后人人都能承受，并且能够毫无痛苦的离开人间这样的一个场面。我们看到这个老老公其实也没有丝毫的痛苦，他还面带笑语，红红扑扑的小嘴在开心的乐着。（左下）接下来这个是我们看到对地上有非常多的金银财宝，但是走过路过的人都没有去看过。最终四个字概括这幅上面的我说一共四个字的概括，这个场面就是路不拾遗的场面。<br>  （右中）我们视线可以看到这幅画的右面，你们能看出来这两个人在干什么吗？跳舞吗？能在跳舞吗？他其实在换衣服，那他们的衣服是从哪来的呢？按照这幅画的释义，他们的衣服是树上生长出来的。就是我走在路上，随手从树上就能拽一件适合自己的衣服就穿上，这就是路上生衣的故事。</p><p>  （右下）然后接下来其实这个帐篷里正在举行的是一场几亿年之后的婚礼。那么这场婚礼的女主人公演就是这个新娘。按照这幅画的释义，他已经 500 岁了，500岁才结婚。但是相比于人这个 84,000 岁的寿命来讲，其实也不算很长。所以说这幅画总体上想表现的就是古代人民对这样一个社会安定、物质文化及其繁荣的这样一个社会的一种幻想，来通过这样的方式给它绘画了出来。</p><p><img src="https://s2.loli.net/2022/10/03/eTD2Vo6Z91EGc7Q.png" alt="万林4.png"></p><p>  接下来我们看我们左手边的这幅壁画。这幅壁画大家一搭眼上看上去有点乱，其实这幅画也是有一定的观看顺序的。这幅画讲的故事是舍身似火的，主人公是三位太子，一个王者的三位太子。那么有一个出城，这时候其中的三太子就看到有一只母老虎非常的饥饿，还在吃自己的孩子来吃一只小老虎。于是我们这个三太子就登上了山顶，从山顶一跃而下，开始把自己摔死了，就当把自己喂给了这只母老虎。所以我们可以在这里看到这块有一个虎头对吧，虎头是一个这块是就是我们三太子对，这个是好，这个是我们从悬崖上跳下来的三太子不要磨。同时我们可以看到三太子把自己喂给老虎之后，他们的父母又说国王和王后赶了过来，王后抱着自己已经摔死了的儿子在痛哭。后来这个他们的父母和当地人为他们建了一集座塔。后来这个三代子就成佛了。就是这幅画的观看顺序，就是从最中间从螺旋上面向后观看。</p><p><img src="https://s2.loli.net/2022/10/03/jAMPEBF1p4UL3Oi.jpg" alt="万林5.JPG"></p><p>  春晚有一个节目可能给大家留上了非常深刻的印象，是一个舞蹈叫只此青绿，它是以千里江山图为创作背景创作的一个舞蹈。那么千里江山图它其实是有它这种画的类别，是有一个学名叫青绿山水画。那我们今天其实看到的千里江山图，已经经过了岁月的这种痕迹，它已经可能有一些变色了。<br>  千里江山图的出现是在盛唐时期，那么我们面前的这幅画其实就也是一幅面，我们面前就是一束青绿山水画，而他的创作年代也正是盛唐。所以说我们就可以看到盛唐时期的这种青绿山水，真正展现在世人面前是什么样子？我们可以看到就是以以青色来表示这种山的层峦叠翠，用绿色去表现水的清波荡漾。非常的清新，我们继续向前参观。<br>  想必大家都看过西游记，在西游记中有一集是大战狮驼岭。那一集有三个妖怪，分别是一只雕一只青狮兽和白象兽。在西游记里他们说他们那个说是青狮兽和白象兽，是文书菩萨和普贤菩萨做记，私自下凡为妖。那我们就可以观察这两幅文书便和普贤便，在普贤便中间所绘的为普贤不算。那下方我们看到他他他的他的这支坐骑是什么？像正是白象，在那幅文书变种，我们也可以看到那个作家也正是青诗。所以我们说在西游记中乃至于菩萨的坐骑这样的细节都不是作者自己杜撰出来的，而是在真实的佛经壁画中真实可考、有评可依的。</p><p><img src="https://s2.loli.net/2022/10/03/jpEeSsyfXlZU37Q.jpg" alt="万林6.jpeg"></p><p><img src="https://s2.loli.net/2022/10/03/kQl7aOHzDu8FeZY.png" alt="万林7.png"></p><p>  那么说到西游记，就不得不提到我们这幅水月观音像这幅水月观音画与水月观音为主体，非常慵懒的躺在这里。同时在我们璞玉观察到的右下角，我们可以看到有两个非常小的小人，大家能猜出来这两个小人这是谁吗？我刚才说的和西游记有关。没错，前方在靠前的正是唐僧右后方向的是孙悟空。同时这里还有一个非常小的来，对，这个是黑吗？大家能猜出这谁是谁吗？</p><p><img src="https://s2.loli.net/2022/10/03/QU6YW1ScVMOvfBs.png" alt="万林8.png"></p><p>  285窟。这个这座窟有非常多的外号，选两个给大家介绍一下，一定是从考古的角度来说，叫做标准窟。那么什么是标准窟就说明他的确切开凿年代是真实可考的。那么其他的一些洞窟，我们没有办法去考证他的开凿年代。所以就以这座洞窟作为基准来进行对比，根据他们所使用材料建筑形制或者是绘画风格的差异来断定其他动物的开凿年代。</p><p><img src="https://s2.loli.net/2022/10/03/L5VUTNIG2gzX4oy.jpg" alt="万林9.jpg"></p><p>  那么从他的绘画审美的角度来说，这座窟也有个外号，外号叫东方的万神殿，我们说他是东方，因为大家可以看到大家可以抬头向上看中间的这种顶称布兜型方形坡？。是一种非常具有中国特色的建筑形式，不能说它是万神殿。我们大家继续抬头向上看，在天地中要绘画多非常多的艺术形象，大家可以来辨认一下。在我的右手所指是佛教中非常常见的艺术形象，飞天的形象。</p><p><img src="https://s2.loli.net/2022/10/03/RxHyAQJbIui2sjG.jpg" alt="万林10.jpg"></p><p>  左上是伏羲，右上是女娲，女娲手持规，伏羲手势矩尺和斗，咱这就是所谓的规天矩地了，就是规矩。那么伏羲的这个胸前，再根据汉文化里头呈现的这个原轮应该是三足乌，在汉文化里头代表的太阳。右边这个是蟾蜍，代表的是月亮。这个是中国的创世之神，人类的人文始祖，他也代表日月至上，等于说他到了佛教里头完全就转变了身份。那直接我们说直接就是成了一个日月之神了。那么他们有什么作用呢？他就是从天上下凡到地上，在黑夜之中，然后给大家提供光明，就是这样的。</p><p><img src="https://s2.loli.net/2022/10/03/Y58LGV6aoWKX7MJ.jpg" alt="万林11.jpeg"></p><p>  （上图是类似的残卷不是壁画）大家顺着我的左手边看，左手边的壁画其实是七幅形式差不多的壁画，称为七幅图。因为它形式差不多，我就选一幅图给大家进行讲解。其实每一幅画的东西都差不多。我们说他们每一幅是有三要素。第一个要素就是上方所绘的佛和菩萨，也就是我们说我们供奉的佛和菩萨。这中间佛的正下方有一段文字，它称为发愿文。它上面写了什么呢？其实写的是很简单。第一件事我是谁？第二件事，我所供养的什么是什么佛和什么菩萨。在我最左手边的那块上，这个文字至今还依然可见。他上面写了我供奉的是无量寿佛。就是说我们说南无阿弥陀佛就是无量寿佛。我写的第三件事，我供奉这个佛和菩萨。诶我想让他们帮我实现什么愿望。那幅画也说了，今生太平，往生极乐。就是这样特别简单，但又很难实现这种愿望</p><p>![IMG_2650.JPG]<img src="https://s2.loli.net/2022/10/03/vPfBzbYp7UHuXot.jpg" alt="万林12.jpg"></p><p>  彭老师和樊老师他们在 99 年的时候发掘的那个九十六窟，就是那个 9 层楼的那个坡。看早期的数据，就是34.5米。但是现在的数据我刚才不说了，是35.5米。为什么呢？就是 99 年对这个工作开始考古发掘，发掘以后我们看了地面，就是我们现在观众进去参观的地面是民国时期形成的。然后我们刚才说了那个佛像是武则天时期塑造的，所以要找到考古，就是要找到武则天时期的地面，这就往下发掘。发掘以后就发现最上面是民国、清代、元代、西夏、唐朝，最后是那这个中间差距刚好是 1 米。所以我们说佛像实际上不是长了1 米。</p><p><img src="https://s2.loli.net/2022/10/03/3UeDf8mYCWdgVx6.jpg" alt="万林13.jpg"></p><p>  照片中C位的圆脸女孩是年轻时的樊锦诗院长</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>看代码框架的碎碎念</title>
    <link href="/posts/23646/"/>
    <url>/posts/23646/</url>
    
    <content type="html"><![CDATA[<p>最近刚进入到看前人代码的阶段，着实把我给看迷糊了，故来梳理+吐槽几句。</p><h1>最基础的结构</h1><p>深度学习训练一个网络最简单的代码大抵是由</p><ol><li class="lvl-3"><p>处理数据的代码</p></li><li class="lvl-3"><p>架设网络各层结构的代码</p></li><li class="lvl-3"><p>定义训练目标（损失函数）的代码</p></li><li class="lvl-3"><p>选择超参数和训练优化器与集成各代码接口进行训练的代码（主函数）。</p></li></ol><p>通常来说三到四个.py文件就足以完成像识别手写数字这样的简单的学习任务，如果愿意这一工作甚至可以在一个脚本中完成。</p><h1>稍微复杂的模型</h1><p>但是我们研究的问题毕竟不会像已经被实现了无数次的识别手写数字这么简单，为了解决各种复杂的问题，我们的代码开始膨胀。</p><h2 id="处理数据的代码">处理数据的代码</h2><p>我们处理的数据可能需要经过处理得到二级数据，或需要基于已有的数据合成新的数据。于是处理数据的代码开始无限的膨胀起来，但是只要思路清晰还是可以在几个脚本之内解决，且可以提供相对简单的端口。</p><h2 id="架设网络各层结构的代码">架设网络各层结构的代码</h2><p>我们的网络不再是简单的全连接和卷积了，我们可能要让它能够随机关闭一些单元，后面层的数据可能还要返回到前面的层，几个网络可能不是以串行的方式组合在一起……</p><p>一个好消息是这其中许多的功能已经被集成在框架的代码里，可以稳定的调用。但坏消息是毕竟是做研究嘛，不自己设计点特别的网络怎么好跑出更好的结果呢，于是代码再次膨胀且没有上线的</p><h2 id="定义训练目标（损失函数）的代码">定义训练目标（损失函数）的代码</h2><p>这里其实在代码的层面不会太复杂，主要是需要动脑子去设计，上限很高。至于下限嘛，方差了解一下。</p><h2 id="选择超参数和训练优化器与集成各代码接口进行训练的代码（主函数）">选择超参数和训练优化器与集成各代码接口进行训练的代码（主函数）</h2><p>这里主要是集成的工作，通常是在一个文件里搞定，为了实现超参数的可选择性有时候也拆分成两个文件来写。</p><h2 id="小结">小结</h2><p>如果只是把模型设计的更复杂、更精巧，其实代码并不会膨胀的太过厉害。而且在研读这样的代码的时候其实只要把握住论文的思路，抽丝剥茧，把各个部分分开来看，其实并不至于陷入其中。整个项目就像一个毛线团，沿着主函数的线头，总能把它解开。</p><h1>能够用于开展实验的代码</h1><p>代码的复杂度从这一层开始爆炸，令人头秃～</p><p>这里的复杂性主要是体现在实验建档和数据的保存以及一些可视化的问题。</p><h2 id="实验建档和数据的保存">实验建档和数据的保存</h2><p>进行实验建档于数据保存这件事情当然是天经地义和势在必行的，但是这项工作所需的代码通常是穿插在许多直接服务于网络运行的代码当中的，而不加注释的良好习惯与多种类继承嵌套的良好习惯通常使我们在阅读代码的时候思路被打断以及百思不得其解它在干什么。</p><h2 id="可视化的问题">可视化的问题</h2><p>这个问题其实相对好解决，主要还是依靠现成的框架，而且其实可以后期再填补进代码，相对来说不会造成太多看代码困惑的问题。</p><h2 id="小结-2">小结</h2><p>这个层次主要是在以往在深度学习知识的学习的时候不曾接触的部分，是需要努力理解并自己能够掌握与修改的部分。</p><h1>完整的框架</h1><p>完整的框架是为了解决一类问题集成了已有的各种算法和数据集的平台，使得后来人能够在此基础上简单的开展自己的实验。</p><p>然而，为了数据集能够公用，算法能够使用公共的接口，在每一种方法和类的设计都参杂了无数的分类讨论。接口的调用通常也就因此会跨越数个文件，很难找到原始方法所在的文件，很难读懂。</p><p>就还是用毛线球的比喻，读一个完整的框架，对于框架里不同的实验就像一根线头衍生出的无数分支，这些分支还公用了“实验建档和数据的保存”等的线段，整个一个缠死了，根本理不出一个头绪来。</p><h1>总结</h1><p>大佬们为我们这些后来者搭建了非常便利的框架——一个庞大而精细的系统。但事实上这框架对我好像并没有想象中助益大，反而让我在庞大系统面前产生了个体的无力感，无力见全貌，无力基于系统做些属于自己的修改。所幸吐槽/整理了这么多之后，我对框架的理解稍稍清晰了，那就继续肝呗</p>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>梳理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Domain Generalization: A Survey</title>
    <link href="/posts/24868/"/>
    <url>/posts/24868/</url>
    
    <content type="html"><![CDATA[<h1>1.Introduction</h1><p><em>Answers to all these questions depend on how well the machine learning models can deal with one common problem, namely the domain shift problem. Such a problem refers to the distribution shift between a set of training (source) data and a set of test (target) data</em></p><p>未知数据域直接能够使模型工作的问题domain shift problem，主要是原数据和目标数据的分布不同</p><p><em>Most statistical learning algorithms strongly rely on an over-simplified assumption, that is, the source and target data are independent and identically distributed (i.i.d.), while ignoring out-of-distribution (OOD) scenarios commonly encountered in practice.</em></p><p>大多数数据的学习给予一个过度简化的假设：源数据和目标数据拥有独立且相同的分布（iid），忽略了超出分布的场景(OOD) 需要在实践中被考虑</p><p><em>A straightforward solution to bypass the OOD data issue is to collect some data from the target domain to adapt a source-domain-trained model</em></p><p>有一个简单的解决方案是从目标域中获取一些数据，来修正原始数据域上训练出的模型DA</p><p><em>DA relies on a strong assumption that target data is accessible for model adaptation, which does not always hold in practice</em></p><p>DA基于一个强假设，那就是目标域的数据是可获取用于模型修正的，但这在实践中不总成立</p><p><em>The goal in DG is to learn a model using data from a single or multiple related but distinct source domains in such a way that the model can generalize well to any OOD target domain.</em></p><p>DG的目标是学习一个从单一数据域或多个相关数据域能够很好的拓展到任意OOD的模型</p><h1>2.Background</h1><h2 id="2-1问题的提出">2.1问题的提出</h2><p>为了医学上的模型迁移到新的病人身上</p><p><em>They performed a thorough investigation into the cross-dataset generalization performance of object recognition models using six popular benchmark datasets. Their findings suggested that dataset biases, which are difficult to avoid, can lead to poor generalization performance.</em></p><p>在六个流行的数据集做了一组实验，发现数据集的差异无法避免，会导致很差的表现</p><h2 id="2-2问题的定义">2.2问题的定义</h2><p><em>Let X be the input (feature) space and Y the target (label) space, a domain is defined as a joint distribution PXY on X × Y.</em></p><p>x为输入空间（特征），y为目标空间（标签），而一个域被定义为分布x与y的joint distribution</p><p><em>For a specific domain PXY , we refer to PX as the marginal distribution on X, PY |X the posterior distribution of Y given X, and PX|Y the class-conditional distribution of X given Y .</em></p><p>对于一个特定的域PXY，我们把px称为x的边缘分布，PY |X 称为给定x的y的后验分布， PX|Y称为给定y的x的类条件分布</p><p><em>In the context of DG, we have access to K similar but distinct source domains S = {Sk = {(x(k), y(k))}}Kk=1, each associated with a joint distribution P (k) XY . Note that P (k) XY 6= P (k′) XY with k 6= k′ and k, k′ ∈ {1, …, K}.</em></p><p>在DG的语境中，我们对K个相似但不同的原始数据域$\mathcal{S} = \left{ S_{k} = \left{ \left( x<sup>{(k)},y</sup>{(k)} \right) \right} \right}_{k = 1}^{K}$每一个都对应一个联合概率分布。而不同数据域之间的分布都是不一样的</p><p><em>The goal of DG is to learn a predictive model f : X → Y using only source domain data such that the prediction error on an unseen target domain T = {xT } is minimized</em></p><p>DG的目标就是学习一个预测模型f : X → Y仅使用源数据域，是的再未知域上预测的误差减到最小</p><p>DG分两种</p><h3 id="Multi-Source-DG">Multi-Source DG</h3><p>方法大多是专用于多源的，默认K&gt;1</p><p><em>using multiple domains allows a model to discover stable patterns<br>across source domains, which generalize better to unseen domains</em></p><p>使用多数据源让模型在多个数据域能够发现稳定的模式，使模型能更好的拓展到未见的领域</p><h3 id="Single-Source-DG">Single-Source DG**</h3><p><em>Essentially, single-source DG methods do not require domain labels for<br>learning and thus they are applicable to multisource scenarios as well.</em></p><p>根本上，单源DG方法不需要标签来学习，所以他们对于多源也同样适用</p><h2 id="2-3Datasets-and-Applications">2.3Datasets and Applications</h2><ul class="lvl-0"><li class="lvl-2"><p>Handwritten Digit Recognition</p></li><li class="lvl-2"><p>Object Recognition目标检测</p></li></ul><p>In VLCS [56] and Office-31 [12], the domain shift is mainly caused<br>by changes in environments or viewpoints.源于环境和视角的转变</p><p>Image style changes have also been commonly studied, such as PACS [37]<br>(see Fig. 1©), OfficeHome [59], DomainNet [60], and<br>ImageNet-Sketch [51]</p><ul class="lvl-0"><li class="lvl-2"><p>Action Recognition动作识别</p></li><li class="lvl-2"><p>Semantic Segmentation语义分割</p></li><li class="lvl-2"><p>Person Re-Identification (Re-ID)行人重识别（比如监控跨摄像头追踪人）</p></li><li class="lvl-2"><p>Face Recognition</p></li><li class="lvl-2"><p>Face Anti-Spoofing人脸活体检测</p></li><li class="lvl-2"><p>Speech Recognition</p></li><li class="lvl-2"><p>Sentiment Classification</p></li><li class="lvl-2"><p>The WILDS Benchmark</p></li><li class="lvl-2"><p>Medical Imaging</p></li><li class="lvl-2"><p>Reinforcement Learning (RL)</p></li></ul><h2 id="2-4Evaluation">2.4Evaluation</h2><p><em>Evaluation of DG algorithms often follows the leave-one-domain-out rule [37]: given a dataset containing at least two distinct domains, one or multiple of them are used as source domain(s) for model training while the rest are treated as target domain(s);a model learned from the source domain(s) is directly tested in the target domain(s) without any form of adaptation</em></p><p>在一个或多个数据集上训练得模型，不加修改的使用在一个数据集上测试</p><h3 id="Evaluation-Metrics">Evaluation Metrics</h3><p>average and worst-case performance</p><h3 id="Model-Selection">Model Selection</h3><p>Trainingdomain validation, which holds out a subset of training data for<br>model selection;</p><p>Leave-one-domain-out validation, which keeps one source domain for model<br>selection;</p><p>Test-domain validation (oracle), which performs model selection using a<br>random subset of test domain data.</p><p><em>Another important lesson from [128] is that specially designed DG<br>methods often perform similarly with the plain model (known as Empirical<br>Risk Minimization) when using larger neural networks and an extensive<br>search of hyperparameters. Therefore, it is suggested that future<br>evaluation should cover different neural network architectures and<br>ensure comparison is made using the same model selection criterion.</em></p><p>特别设计的DG可能表现和一个简单的模型使用大一点的网络效果一样。所以在评估的时候最好和不同的神经网络一起比较，并使用相同的比较模型</p><h2 id="2-5-Related-Topics">2.5 Related Topics</h2><ul class="lvl-0"><li class="lvl-2"><p>Supervised Learning</p></li><li class="lvl-2"><p>Multi-Task Learning</p></li></ul><p><em>Intuitively, MTL benefits from the effect of regularization brought by<br>parameter sharing [129], which may in part explain why the MTL<br>paradigm works for DG.</em></p><p>特征的共享可能MTL在DG中有用</p><p>Transfer Learning (TL)</p><p><em>a couple of recent DG works [141], [142] have researched how to<br>preserve the transferable features learned via large-scale pre-training<br>when learning new knowledge from source synthetic data for<br>synthetic-to-real applications</em></p><p>几个DG网络研究如何在学习新知识时保留大型网络中可迁移的特征</p><p>Zero-Shot Learning</p><p>两者不同，ZSL主要是标签域在变动，而DG主要是数据域的变化</p><p>Domain Adaptation (DA)</p><p>Test-Time Training</p><p>blurs the boundary between DA and DG</p><p>均假设目标域不可见，但是会在运行测试集的时候对网络进行微调（在线），使用的数据集和DA高度重叠，但是要求算力较高，调整的时间较短</p><h1>3.METHODOLOGIES: A SURVEY</h1><h2 id="3-1Domain-Alignment">3.1Domain Alignment</h2><p><em>where the central idea is to minimize the difference among source<br>domains for learning domain-invariant representations (see Fig. 2).</em></p><p>中心思想是使用来学习的不同源域之间的差异最小化以获得跨领域不变的表示方法</p><p><em>The motivation is straightforward: features that are invariant to the<br>source domain shift should also be robust to any unseen target domain<br>shift</em></p><p>这么做的动机很简单，在源域变换中不变的特征应该足够鲁棒迁移到不可见的目标域中</p><p>PS：这个方法训练的时候需要标签</p><p><em>To measure the distance between distributions and thereby achieve<br>alignment, there are a wide variety of statistical distance metrics for<br>us to borrow, such as the simple `2 distance, f -divergences, or the<br>more sophisticated Wasserstein distance [217].</em></p><p>为了衡量两个分布之间的差距以达成适配，有许多统计学距离尺度，比如l2，f<br>-divergences，sophisticated Wasserstein distance</p><h3 id="3-1-1-What-to-Align">3.1.1 What to Align</h3><p>域是一个联合分布，我们把它表示成<br>$$<br>\mathcal{S}=\left{S_k=\left{\left(x^{(k)}, y<sup>{(k)}\right)\right}\right}_{k=1}</sup>K<br>$$</p><p><em>A common assumption in DG is that distribution shift only occurs in the<br>marginal P (X) while the posterior P (Y |X) remains relatively stable</em></p><p>一个通常的假设是在DG中分布变化只发生在x的边缘分布，而后验分布P (Y<br>|X)通常很稳定</p><p>（个人理解：就是说给定x后y是唯一的，但是x中有很多无关这个关系的信息，我们需要去Align出有用的消息）</p><p>当然还有一些换假设的，认为y本身不变，y是x原因…感觉crowd<br>c用不上也没大看懂原理</p><h3 id="3-1-2-How-to-Align">3.1.2 How to Align</h3><p>Minimizing Moments</p><p>缩小moment（a quantitative measure of the shape of a set of<br>points.），简单来说就是学习一个映射函数来减小分布之间均值和方差的差</p><p>Minimizing Contrastive Loss</p><p>给定一组锚，找到办法标定出与锚相同的数据和不同的数据，学习使差距减小和变大</p><p>Minimizing the KL Divergence 学习出一个方法使所有的域都能够服从高斯分布</p><p>Minimizing Maximum Mean Discrepancy (MMD) 先把数据映射到reproducing<br>kernel Hilbert space再得到距离</p><p>Domain-Adversarial Learning 使用对抗网络来减小差距</p><p>Multi-Task Learning</p><p>has also been explored for domain alignment [53], [206]. Different<br>from directly minimizing</p><h2 id="3-2-Meta-Learning（没看懂）">3.2 Meta-Learning（没看懂）</h2><p><strong>Episodes Construction</strong></p><p><strong>Meta-Representation</strong></p><h2 id="3-3-Data-Augmentation">3.3 Data Augmentation</h2><p>The basic idea in data augmentation is to augment the original (x, y)<br>pairs with new (A(x), y) pairs where A(·) denotes a transformation,<br>which is typically labelpreserving.</p><p>（这个感觉上对风格不同的照片会有帮助，或许可以尝试把天气什么的考虑进去做个增强？）</p><ul class="lvl-0"><li class="lvl-2"><p>Task-Adversarial Gradients</p></li><li class="lvl-2"><p>Domain-Adversarial Gradients</p></li></ul><p>When it comes to multisource DG where domain labels are provided, one<br>can exploit domain-adversarial gradients to synthesize domainagnostic<br>images.</p><ul class="lvl-0"><li class="lvl-2"><p>Random Augmentation Networks</p></li><li class="lvl-2"><p>Off-the-Shelf Style Transfer Models</p></li><li class="lvl-2"><p>Feature-Based Augmentation**</p></li></ul><h2 id="3-4-Ensemble-Learning">3.4 Ensemble Learning</h2><p>用不同的初始化参数多学几个模型，结果一平均</p><ul class="lvl-0"><li class="lvl-2"><p>Exemplar-SVMs</p></li><li class="lvl-2"><p>Domain-Specific Neural Networks</p></li></ul><p>A common practice is to learn domain-specific neural networks, each<br>specializing in a source domain [61], [198]. Rather than learning an<br>independent CNN for each source domain [198], it is more efficient,<br>and makes more sense as well, to share between source domains some<br>shallow layers [61], which capture generic features [139].</p><p>多学几个模型，共用头几层，然后训练</p><h3 id="Domain-Specific-Batch-Normalization">Domain-Specific Batch Normalization</h3><p>one for each source domain for collecting domain-specific statistics.<br>This is equivalent to constructing domain-specific classifiers but with<br>parameter sharing for most parts of a model except the normalization<br>layers.</p><p>共享大多数参数，但是在归一化层对不同的域做区隔</p><h3 id="Weight-Averaging">Weight Averaging</h3><p>aggregates model weights at different time steps during training to form<br>a single model at test time [239]. Unlike explicit ensemble learning<br>where multiple models (or model parts) need to be trained, weight<br>averaging is a more efficient solution as the model only needs to be<br>trained once. In [205], the authors have demonstrated that weight<br>averaging can greatly improve model robustness under domain shift. In<br>fact, such a technique is orthogonal to many other DG approaches and can<br>be applied as a postprocessing method to further boost the DG<br>performance.</p><h2 id="3-5-Self-Supervised-Learning？">3.5 Self-Supervised Learning？</h2><p>Recent state-of-the-art self-supervised learning methods [244],<br>[245] are mostly based on combining contrastive learning with data<br>augmentation. The key idea is to pull together the same instance (image)<br>undergone different transformations (e.g., random flip and color<br>distortion) while push away different instances to learn instanceaware<br>representations. Different from predicting transformations such as<br>rotation, contrastive learning aims to learn transformation-invariant<br>representations. Future work can explore whether invariances learned via<br>contrastive learning can better adapt to OOD data.</p><p>最近最好的自监督学习就是基于对抗学习和数据增强</p><h2 id="3-6-Learning-Disentangled-Representations">3.6 Learning Disentangled Representations</h2><p><em>This approach was later extended to neural networks in [37]. One can<br>also design domain-specific modules such as in [207] where<br>domain-specific binary masks are imposed on the final feature vector to<br>distinguish between domain-specific and domain-invariant components.<br>Another solution is to apply low-rank decomposition to a model’s weight<br>matrices in order to identify common features that are more<br>generalizable [208].</em></p><p>可以设计一个domain-specific的模块一个general模块，最后检测最后的特征层有哪些是general有哪些是specific的</p><h2 id="3-7-Regularization-Strategies">3.7 Regularization Strategies</h2><h2 id="3-8-Reinforcement-Learning">3.8 Reinforcement Learning</h2><h1>4 THEORIES</h1><h1>5 FUTURE RESEARCH DIRECTIONS</h1><h1>6 CONCLUSION</h1>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论文摘录</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>8~9月读书摘抄</title>
    <link href="/posts/21143/"/>
    <url>/posts/21143/</url>
    
    <content type="html"><![CDATA[<h1>潜规则（推荐阅读原文，可读性高）</h1><h2 id="摘录">摘录</h2><p>  合法地祸害别人的能力，乃是官吏们的看家本领。这是一门真正的艺术，种种资源和财富正要据此分肥并重新调整。</p><p>  中国民间有句老话，叫作&quot;身怀利器，杀心自起&quot;。在如此实力悬殊的战争中，自己最多不过蹭破点皮，俘获的却是众多的子女玉帛，这样的仗自然就特别爱打，也特别能打。官吏们要顶住多打几仗的诱惑，很有必要定力过人。</p><p>  其实，中国历代老狼的经验很丰富，完全明白这个道理。那些为天子牧民或者叫牧羊的肉食者，都知道羊是狼生存的根本------简称&quot;民本&quot;。大家都懂得爱护羊群的重要意义。奈何抵抗不住眼前绵羊的诱惑，也抵抗不住生育狼崽子的诱惑。这也是有道理的：我不吃，别的狼照样吃；我不生，别的狼照样生。个体狼的利益与狼群的集体利益未必一致。如果我的节制不能导致别人的节制，我的自我约束对羊群来说就没有任何意义，徒然减少自己的份额而已。在老狼忍不住饕餮的时候，我可以听到一声叹息：它们要是变成刺猬，俺们不就变成清官了么？</p><p>  总之，从经济方面考虑，清官是很难当的。那时的正式制度惩罚清官，淘汰清官。硬要当清官的人，在经济上必定是一个失败者。当然，这里算的都是经济账，没有重视道德操守。道德操守是官僚集团自始至终卖力挥舞的一面大旗，它翻滚得如此夺目，根本就不容你不重视。我完全承认，道德的力量是有效的，海瑞的刚直不阿可以为证。但道德的力量又是有限的，海瑞的罕见和盛名也可以为证。</p><p>  恶政好比是一面筛子，淘汰清官，选择恶棍。</p><p>  在权力大小方面，皇上处于优势，官僚处于劣势。但是在信息方面，官吏集团却处于绝对优势。封锁和扭曲信息是他们在官场谋生的战略武器。你皇上圣明，执法如山，可是我们这里一切正常，甚至形势大好，你权力大又能怎么样？我们报喜不报忧。我们看着领导的脸色说话。说领导爱听的话。我们当面说好话，背后下毒手。难道有谁能天真地指望钱能向皇上汇报，说我最近成功地完成了两次敲诈勒索么？如果干坏事的收益很高，隐瞒坏事又很容易；如果做好事代价很高，而编一条好消息却容易，我们最后一定就会看到一幅现代民谣所描绘的图景：&quot;村骗乡，乡骗县，一级一级往上骗，一直骗到国务院。</p><p>  那么清官究竟在哪里呢？清官光荣地牺牲了，成了大家的好榜样。</p><p>  令人拍案叫绝的是，如今的官员和整个官场根本就用不着翻检什么古籍，他们无师自通，与明清官场患上了一模一样的病症，就连&quot;三节&quot;也和明清一样选在春节、端午和中秋，绕开了官定地位远高于端午的元旦、五一和国庆节。这真是莫名其妙，妙不可言。持续数十年的决裂传统和培育新人的凶狠努力，居然只造就了一点行贿名称和技巧上的差距。从发展速度判断，弥补这点差距，赶上并超过明清官场的水平，在不远的将来就可以实现，我对这一点要比&quot;超英赶美&quot;乐观得多。</p><p>  从利害关系的角度看，对抗当然是要倒霉的，听话才有出路，自己也可以跟着沾点光。但是从道德是非的角度看，欺下媚上毕竟有点不对劲。怎么办？这是每个官员都躲不开的实际问题，也是一个可以逼迫大多数人显现原形的问题。如果碰上思想不那么纯洁，立场不那么坚定的人，恐怕就会冒出这样的念头：我对抗领导，然后丢掉饭碗，真能起到什么好作用么？白白牺牲了自己，换上来一个新的，说不定一点良心也没有，欺压老百姓更加残酷，还不如我呢。为了减轻东阿人民的损失，我要坚守岗位，多跟领导合作，少搞对抗。------如此一想，良心竟然被我们糊弄平整了，我们也就可以坦然地媚上欺下了。这种官场生存策略的转变正好与晏氏转型相对应。</p><p>  皇上可以代表天道的高论，在清末民初就有很多人不信了。但是问题并没有彻底解决。民国号称是人民的国，偏偏不肯让人民当家作主，说要经过&quot;军政&quot;和&quot;训政&quot;这两个历史阶段之后，才能&quot;还政于民&quot;，实行宪政。这套说法的理论根据是三民主义。主义云云，听起来很像是天道的变种。中国共产党人揭露说，这套为&quot;还政于民&quot;设置条件的说法，本质是为一党独裁和蒋家王朝的专制打掩护。当然，这种揭露是很深刻的，但我觉得，宣称自己是老百姓的代理人，而且是临时代理人，总比宣称自己是天道的代表进了一步。毕竟他失去了可以永远领导老百姓的借口，失去了永远也不还政于民的理由。</p><p>  孔子和毛泽东倡导的人格理想，都很合时宜地告诉人们如何处理当时最基本的人际关系，并且很有力地证明这种处理方式合乎天道人心或者历史规律，具有终极价值。</p><p>  现在，我们离宗族大姓毗邻而居，宗亲世交触目皆是的时代已经很远了，我们离革命同志团结一心、兴无灭资、推翻三座大山的时代也不近了。出门上班，满眼小商小贩雇主雇员，下班上路，到处是行色匆匆的路人和讨价还价的顾客。想叫一声同志，招呼一声兄弟，真不知冲谁开口。</p><p>  孔夫子和毛主席没有教我们在这样的社会里怎样做人，没有来得及为我们树立一种合乎此时此境的人格理想，并把它与不知躲在何处的终极价值联系起来。</p><p>  呜呼，我们失去了精神支柱。</p><p>  我能拿出什么样的理由来劝阻呢？为人民服务？笑话。毫不利己专门利人？神经病。“五讲四美三热爱”、争当&quot;四有新人&quot;？大傻帽。天理良心，损阴德折阳寿，伤天害理，不得好死，断子绝孙，下十八层地狱，除了这些古人的话，我想不到什么更有力量的说法。我好像出了毛病，或者是我们现在的意识形态出了毛病，很容易就能找到替损人利己的行为辩护的理由，但是却找不到有力的反对理由。天理良心，这是宋明理学的东西，被几百年来的英雄好汉斥为假道学的东西。损阴德折阳寿下地狱，这是迷信，传媒们正在起劲地反对着。反对了，打倒了，然后呢？光天化日之下还剩下什么？</p><p>  所谓抬头三尺，即有神明，善有善报，恶有恶报，这些话在那时人们心目中的分量，绝对不同于现在的说笑。这种神秘的威胁是永远无法证实，也永远无法打消的，它永远是一把悬在贪官污吏头上的剑：欺压百姓不得好死。就算得了好死，地狱里也有油锅等着你。你可以不信，但是又不敢完全不信。“就是&quot;迷信&quot;的力量。我们可以说这是神道设教，说这是胡扯，但是你发明一个既不胡扯又有威慑力的说法试试？”</p><h2 id="感想">感想</h2><p>  这本书感觉已经把潜规则的来龙去脉说得很清楚了，无非既要把良心糊弄平整，又要穷奢极欲的情况下，老爷们官官相护地构架出了一套心照不宣的剥削体系。人们为何总是把自己的聪明才智挥霍在这种地方，处心积虑把伤害别人变得合法，合法的那么心安理得。</p><h1>是我把你蠢哭了嘛（不建议花时间看原书，可快速翻阅)</h1><h2 id="摘录（公正世界假说必看）">摘录（公正世界假说必看）</h2><h3 id="为什么批评比表扬效力更强">为什么批评比表扬效力更强</h3><p>  压力引起皮质醇分泌会对大脑产生直接影响会加强人的注意力，让记忆更加鲜明持久。而在我们受到批评时，分泌的皮质醇以及其他激素可能也会不同程度地导致相同情况的发生，让我们经历实实在在的身体反应、变得敏感，且相关记忆得到增强</p><p>  我们亲身经历负面事件时，会相应地产生种种情绪和感受，海马和杏仁核又开始活跃起来，最终在情绪上增强记忆，令记忆更为鲜明。</p><p>  获得赞扬之类的好事也会引起神经系统的反应，通过催产素（oxytocin）让我们感到愉悦，但是催产素起作用的方式没那么强烈，并且较为短暂。化学特性决定了催产素在大约五分钟内就会被排出血液循环；相反，皮质醇可以持续作用超过一小时，有时甚至长达两小时，其效应远比催产素更持久。</p><p>  什么事一旦成了规范，爱新奇的大脑就会倾向于通过习惯化过程将其滤除。因为既然一直发生，忽视它也安然无恙，为什么还要浪费宝贵的脑力资源来关注呢？（表扬和赞成是大多数的社会规范）</p><p>  轻度赞扬既成规范，批评就会变得更具冲击力，因为那是出格的。</p><p>  我们的大脑确实只会根据我们所知道的情况做出判断，而我们所知道的又都是基于自身的结论和经验，因此往往会基于自己的所作所为去评判他人的行为。那么，假如我们自己是出于社会规范的要求而表现得礼貌、说一些赞美之词，那其他人的行为是不是也都出于同样的考量呢？于是，我们获得的每一份赞美都显得有点可疑：它是不是真心的？而假如有人批评了你，那就不仅说明你做得糟糕，而且已经糟糕到让人宁愿破坏社会规范也要指出的程度。这下，批评的分量再次重过了赞扬。</p><h3 id="为什么蠢人有时候更自信">为什么蠢人有时候更自信</h3><p>  有人或许以为最后一定是最聪明的人把持着事情的进展方向，因为越聪明的人，完成的工作就越好。可我们常看到的实情却似乎是反直觉的，越是聪明的人，对自己的观点不太自信的可能性越高，越容易给人留下不那么自信的印象，因而不被信任的概率也就越高</p><p>  人们在意自己的社会地位和财富，而看上去比自己更聪明的人则可能构成一种威胁。那些体格更高大、更强壮的人虽然令人心惊胆战，但却是一种已知的属性。</p><p>  可是，一个比自己聪明的人就是个未知数了，他们的行为方式让你难以预料或者根本无法理解，大脑完全搞不清楚他们会不会带来危险。于是，&quot;万事小心好过事后后悔&quot;的古老本能便被激活，触发怀疑与敌意。当然一个人也可以通过学习钻研从而让自己变得更加聪明，但这远比改善体格更复杂，也更不确定。举重让你的胳膊强壮，而学习和聪明之间的联系就要松散得多。</p><h3 id="达宁-克鲁格效应">达宁-克鲁格效应</h3><p>  智力欠佳的人不仅在智力的能力上有所欠缺，而且在认识自己智力不足的能力上也有不足。再加上大脑的自我中心倾向也会掺和进来，对自己产生负面意见的可能性进一步受到抑制。况且，要认识到自己的局限和他人能力的优秀本来就是件需要智力的事情。于是我们就看到有的人在自己全无亲身经验的事情上自信满满地与他人激烈争论，哪怕对方已经在该问题上钻研了一辈子。我们的大脑只有自身经验可以借鉴，而我们的基本假设是人人都和自己一样。所以假如自己是个傻瓜的话，就会…</p><p>  聪明人&quot;对世界的感知可能也类似，但是表现为另一种形式。如果一个聪明人觉得某件事很简单，那么他们很可能会认为其他人也有同样的感觉。他们以自己的理解水平为标准，因而觉得自己的聪明程度属于普通</p><p>  此外，聪明的人普遍养成了学习新事物、获取新知识的习惯，因而更有可能认识到自己不是什么都懂，知道在各种领域都还有好多东西需要学习，于是他们在下结论、做声明时就不敢那么信誓旦旦。</p><h3 id="解释笑话如同解剖青蛙。有助于你理解，但青蛙死了">解释笑话如同解剖青蛙。有助于你理解，但青蛙死了</h3><h3 id="嘲讽和谩骂的来处">嘲讽和谩骂的来处</h3><p>  我们不仅意识到自己的集体身份，还知道自己在集体中所处的位置。</p><p>  这样一来，如果有谁做出集体不予认可的行为，那么既是对集体&quot;完整性&quot;的威胁，也提供了一个机会让其他成员可以踩着不称职者的肩提升自己的地位。于是，谩骂和嘲弄就来了。</p><h3 id="公正世界假说">公正世界假说</h3><p>  大脑有一种内在假定，认为世界是公平公正的，善有善报、恶有恶报。这种偏误有助于人们发挥社群作用，因为它有震慑和阻止恶行发生的意义，还让人愿意行善</p><p>  可惜，这种假定并不真实。恶行不一定受到惩罚，好人也常常遇到坏事。然而偏见扎根于大脑深处，让我们深信不疑。于是，当我们看到某个无辜的人遭遇可怕的不幸时，脑中就会出现不和谐音：世界是公平的，但发生在这个人身上的事情却不是。大脑可不喜欢不和谐，于是产生了两个选项：可以认为世界终究还是无情和随机的，也可以认定受害者肯定是做了什么坏事才罪有应得。后者虽然更无情，却让我们继续对世界抱有岁月静好的（错误）假定，因此我们会指责遭遇不幸的受害者。</p><p>  举例来说，当人们能够做些什么减轻受害者的痛苦，或是了解到受害者其后会获得赔偿时，对受害者的批评就比较少。而如果人们毫无办法帮助受害者，那么就会对其发起更严重的抨击。尽管看起来特别残酷，但与上述假说一脉相承的是，受害者如果没有光明的结局，那么他们必然罪有应得，难道不是吗？</p><p>  人们还更倾向于指责那些让自己产生强烈认同感的受害者。看见倒下的树砸中的是一个与自己年龄、种族、性别不同的人时，产生同情相对容易得多；而如果看到一个和自己年纪、身高体型、性别均相同的人，开着同样的车子撞上一栋和自家同样的房子时，指责对方愚蠢无能的可能性则大大提高，尽管毫无证据支持自己的这种反应。</p><p>  在前一个例子中，没有哪一点可以套用到我们自己头上，那就不妨怪罪事情的发生源自随机的巧合，毕竟影响不到我们。后一个例子却很容易联想到自己，所以大脑想要合理地将其解释为受害者的个人失误。必然是那个人自己的错，否则随机巧合不就也可能发生在我们身上了吗？单是想到这点就难受。</p><p>  可见，尽管我们的大脑有群居、友好的意愿，但它太在乎维护认同感和保持内心的平静了，若有什么人或事对此造成威胁，它宁愿让我们做出不公正的对待。</p><h3 id="对抑郁症的误解">对抑郁症的误解</h3><p>  大脑为了避免替受害者感到难过，会狠狠地扭转思维。而另外一种表现方式，就是给那些终结生命的人贴上&quot;自私&quot;的标签。</p><p>  如果自杀只因为那些人自我放纵或冷酷自私，那就是他们个人的问题了，不会波及我------这么一想，自我感觉就好多了。</p><h2 id="感想-2">感想</h2><p>  这本书把很多我脑海中已有但很模糊的的观念用科学的方式给出了可能的成因，其中最有价值的一点就是“世界公平假说”。它令我惊觉，有时候我会觉得有的人“自作自受”，原来可能只是我大脑想要合理地将某件事解释为受害者的个人失误，而不是同样的厄运也有可能降落在我身上。我也真的会特别在乎维护认同感和保持内心的平静……</p><h1>送你一颗子弹（推荐阅读原书，有趣）</h1><h2 id="摘录-2">摘录</h2><p>  再真诚的忧郁或者狂躁，也因为注视着你的眼睛，变成了一种表演，以至于你自己都忘记它是一种感受还是一种姿态</p><p>  人渴望被承认，也就是别人的目光，但是同时，当别人的目光围拢过来的时候，他又感到窒息，感不到自由</p><p>  集体生活中的&quot;强制性交往&quot;迫使你想独处的时候不得不面对他人，而孤魂野鬼的生活使你在想跟人说话的时候，不得不拿起电话，一个一个往下扫名字，并且自言自语：这个人有空吗？他呢？她呢？他？她？他？上次是我主动约他吃饭的，这次再约人家会不会觉得很烦？而且，其实我们好像也没有什么可说的？</p><p>  一切洗脑的成功要旨，不过在于帮助人们逃避自由。当一个体系能够用逻辑自洽的方式替你回答一切问题、并且保证这些答案的光荣伟大正确的时候，的确，为什么还要去承受&quot;肩负自由的疲惫&quot;呢？</p><p>  春天来的时候，总觉得会发生点什么，但是到头来，什么都没有发生，然后就觉得自己错过了点什么。</p><p>  大学的时候，一个朋友和男友分手，是他主动提出来的。她问为什么，他说：你所能想到的全部理由，都是对的</p><p>  自我是一个深渊，它如此庞大，爱情不可填补</p><p>  瞧瞧那帮男留学生，一个个长得丧权辱国的</p><p>  后来一个网友整理出了男人长相的几个档次：丧权辱国、闭关自守、韬光养晦、为国争光、精忠报国</p><p>  我毕生的理想，就是找个高高大大的男生，他就那么随便一帅，我就那么随便一赖，然后岁月流逝，我们磨磨蹭蹭地变老。</p><p>  不断有人跳出來说：'我们凭什么要关心政治？就爱吃喝玩乐自己挣钱自己花怎么了？！“当然，享乐主义是人权。谁也无权干预。但是千万不要以为&quot;政治冷演&quot;就是没有政治态度，冷漠就是你的态度。更重要的是，享乐主义得以存在，是有一系列公共制度的前提的，而这些前提是政治斗争的结果。以为私人生活与政治没有关系的人，忘记了私人领域从边界的界定到秩序的维护都是政诒问题，难道60年代全中国人穿灰黑蓝和今天大家穿得花枝招展仅仅是&quot;个人品位&quot;的不同？今天的中国从房价、到学术腐败、到电话费、到你在医院要排多久的队、到奴工、到孩子上学、到交通…哪一个归根结底不是&quot;政治向题”？那些&quot;我就是我，去他妈的政治&quot;的说法，就像是&quot;我就是我，去他妈的空气&quot;一样，貌似充满个性，其实无比滑稽。我理解在一个关心政治成本太高、追求个人发展动力很大的时代里大多数人的政治冷漠，但是我不能理解为这种冷漠而感到的洋洋得意。</p><p>  也许，他也只有通过&quot;不想&quot;来逃避这件事情的沉重，因为一个人认识论的飞跃恰恰就发生在&quot;想&quot;的那一刻，因为人道主义的起点在于&quot;一个&quot;人面对另&quot;一个&quot;受苦的人并且心里&quot;咯噔&quot;一声：如果我是他呢？</p><p>  讨论所有这些问题时,突然想到闹同学以前说到的一个玩笑。美国女人嫁人之后都要随丈夫姓，但是一个女权主义者抗议说：我不跟你姓，我要捍卫自己的权利，姓原来的姓！但是丈夫回答道;可是你原来的姓，是你父亲的姓，跟他姓本身，不过是父权制度的另一种表现形式而已！</p><p>  自由这个东西的神奇，不在于它会带来多少洪水猛兽，而在于，这些洪水猛兽出现以后，你发现它其实也不过如此</p><p>  别人往往记住了说话的语气，却忘记了这语气之下的信息。</p><h2 id="感想-3">感想</h2><p>  一个有趣的灵魂把自己的思考与感受用干脆利落的语言展示出来，有时候甚至还有些俏皮：）</p>]]></content>
    
    
    <categories>
      
      <category>读书</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>浅记录2022暑假</title>
    <link href="/posts/53677/"/>
    <url>/posts/53677/</url>
    
    <content type="html"><![CDATA[<h1>Part1 一次还不错的实习</h1><p>  在田间地头行走，被带刺的棘草轻轻抚摸。在雨后初霁的清晨，被湿润的泥土赠与了一双混凝土结构的鞋套。在“12点准点开餐”的饭厅，被先行一步的同学们悉心教会了残羹冷炙是为何物。</p><p>  而“世界以痛吻我，要我报之以歌”，泰戈尔如是说。</p><p>  乡间的风也便徐徐吹进我的心坎，停留片刻，又带着我明媚的好心晴吹进了田野，掀起阵阵稻浪。</p><p>  夏夜的星星也便明亮了起来，摘不下来，不如放一阵烟花，送几颗星星上天。</p><p>  写到这里，似乎这次实习让我印象深刻的东西似乎与遥感没什么关系。且留几个关键词吧，“无人机”“全站仪”“千寻”“通过多种技术路径实现遥感成图”。：）</p><h1>Part2 一阵还算认真的学习</h1><p>  该看的论文没看几行，单词查了一大堆，可惜没进脑子</p><p>  该敲的代码没敲几排，错误爆了一大串，还得谷哥帮我</p><p>  该搭的环境没搭几分钟，系统崩溃了好几次，没事从头再来</p><h1>Part3 一次令人摸不着头脑的隔离</h1><p>  码是绿的，人是低风险来的，隔离是马上的。什么，我朝发白帝的时候白帝还说自己是低风险，暮到江陵的时候,江陵说白帝它……</p><p>  那没事了</p><p>  载去隔离的悠悠路上，无意间注意到一位可能有着4、5个微信账号的小姐姐向着至少5、6个人传达着自己要隔离的消息（可能也许大概）。</p><p>  涨见识了。</p><p>  每天午后快乐的腾讯会议如期而至，开会和疏解心情两者放在一起不会八字不合嘛?真的为难防疫工作人员了</p><p>  不如算了</p><p>  隔离无聊不如搞点事情，搭了一个个人博客。没错，就是你正在看的这个。</p><p>  假结束了</p>]]></content>
    
    
    <categories>
      
      <category>生活</category>
      
    </categories>
    
    
    <tags>
      
      <tag>周期总结</tag>
      
      <tag>季度总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>简单记录一下本博客的搭建过程</title>
    <link href="/posts/57019/"/>
    <url>/posts/57019/</url>
    
    <content type="html"><![CDATA[<h1>搭骨架</h1><ol><li class="lvl-3">在官网上下载node.js， 在本步骤中会下载好node和npm两个工具， 在命令行中使用npm -v来查验</li><li class="lvl-3">使用命令行输入<code>npm install -g cnpm --registry=https://registry.npm.taobao.org</code>来安装cnpm，并使用了淘宝镜像源加速</li><li class="lvl-3">命令行输入<code>cnpm install -g hexo-cli</code>安装hexo</li><li class="lvl-3">找一个地方创建存放blog的文件夹，之后的操作若无说明均在blog文件层操作</li><li class="lvl-3">命令行输入<code>hexo init</code>初始化获得博客基本框架，这个时候使用<code>hexo s</code>就能看到本地接口的博客界面啦</li></ol><h1>代码托管</h1><ol><li class="lvl-3"><p>在git中创建仓库，仓库名一定要设置为git的用户名</p></li><li class="lvl-3"><p>在文件中找到_config.yml, 在文件的最末尾处修改和添加:</p></li></ol><p>···</p><pre><code class="hljs">type: gitrepository: 代码的url或sshbranch: master</code></pre><p>···</p><ol start="3"><li class="lvl-3"><p>安装提交代码的插件<code>cnmp install --save hexo-deployer-git</code></p></li><li class="lvl-3"><p>命令行<code>hexo d</code>推送本地文件到仓库，然后就可以用&quot;<a href="http://xn--eqr924avxo.github.io">用户名.github.io</a>&quot;远程访问博客了</p></li></ol><h1>换博客主题</h1><ol><li class="lvl-3"><p>查找论坛或者hexo官网找到合眼缘的主题找到对应的git库</p></li><li class="lvl-3"><p>git clone该库到blog/themes中</p></li><li class="lvl-3"><p>在_config.yml中的theme处修改为你要用的库</p></li><li class="lvl-3"><p>重新推送你的库到git中就好了</p></li><li class="lvl-3"><p>具体页面的配置参考你的主题作者提供的参考</p></li></ol><h1>一些简单的使用</h1><ol><li class="lvl-3"><p><code>hexo clean</code>清除已有的文件</p></li><li class="lvl-3"><p><code>hexo g</code>重新生成</p></li><li class="lvl-3"><p><code>hexo s</code>在本地预览</p></li><li class="lvl-3"><p><code>hexo d</code>推送到git库</p></li></ol><p>注：前三个为一套，可以每次修改配置的时候进行操作。如果只是写好单篇博客上传则只用4即可</p><h1>一些注意事项</h1><ol><li class="lvl-3"><p>建议使用ssh作连接，在git改变安全机制之后url不大好用，至少本人找不到好的解决方案应用到博客的创建</p></li><li class="lvl-3"><p>建议找主题的时候找参考写的比较详细，适合和我一样的入门者做一些基础的设置</p></li></ol><h1>引用</h1><ol><li class="lvl-3"><p><a href="https://www.bilibili.com/video/BV1Yb411a7ty?spm_id_from=333.880.my_history.page.click">可以全部follow的b站视频</a></p></li><li class="lvl-3"><p><a href="https://github.com/fluid-dev/hexo-theme-fluid">我使用的主题</a></p></li></ol><h1>后续的一些补充</h1><ol><li class="lvl-3"><p>不建议在管理员权限下创建博客，直接正常的权限创建即可。若在管理员权限下则不利于在其它的编辑器下直接修改文件</p></li><li class="lvl-3"><p>建议更换hexo内置的markdown渲染引擎，方法参考<a href="http://t.csdn.cn/QayjR">文章</a>。原始的引擎有些markdown语法无法正常渲染成字符</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>杂</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
